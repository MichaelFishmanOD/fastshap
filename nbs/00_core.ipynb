{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_Core\n",
    "\n",
    "> This module contains helper functions for preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'salary'\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = IndexSplitter(list(range(800,1000)))(range_of(df))\n",
    "to = TabularPandas(df, procs, cat_names, cont_names, y_names=\"salary\", splits=splits)\n",
    "dls = to.dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we train our initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.374005</td>\n",
       "      <td>0.399195</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = tabular_learner(dls, layers=[200,100], metrics=accuracy)\n",
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we begin using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get our predictions in check for our model. We do this by passing in `SHAP` data. This has an option to pass in a test `DataFrame` or `DataLoader`. If none passed in, it will assume the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _prepare_data(learn:Learner, test_data=None):\n",
    "  \"Prepares train and test data for `SHAP`, pass in a learner with optional data\"\n",
    "  dtype = ''\n",
    "  if isinstance(test_data, pd.DataFrame): dtype = 'pandas'\n",
    "  elif isinstance(test_data, TabDataLoader): dtype = 'dl'\n",
    "  elif test_data is None: dtype = 'train'\n",
    "  else: raise ValueError('Input is not supported. Please use either a `DataFrame` or `TabularDataLoader`')\n",
    "  cols = learn.dls.cat_names + learn.dls.cont_names\n",
    "  X_train_cat, X_train_cont, _ = learn.dls.one_batch()\n",
    "  X_train = [X_train_cat, X_train_cont]\n",
    "  X_train = pd.DataFrame(np.concatenate([v.to('cpu').numpy() for v in X_train], axis=1), columns=cols)\n",
    "  if dtype == 'pandas':\n",
    "    dl = learn.dls.test_dl(test_data)\n",
    "  elif dtype=='dl':\n",
    "    dl = test_data\n",
    "  else:\n",
    "    dl = learn.dls[1]\n",
    "    if len(dl) * learn.dls.bs > 256: \n",
    "      test_data = dl.dataset.all_cols.sample(256, replace=False)\n",
    "      dl = learn.dls.test_dl(test_data)\n",
    "  X_test = tensor(dl.cats).long(),tensor(dl.conts).float()\n",
    "  X_test = pd.DataFrame(np.concatenate([v.to('cpu').numpy() for v in X_test], axis=1), columns=cols)\n",
    "  return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.dls.test_dl(df.iloc[:100])\n",
    "X_train, X_test = _prepare_data(learn, dl)\n",
    "test_eq(len(X_train), 64)\n",
    "test_eq(len(X_test), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = _prepare_data(learn, df.iloc[:100])\n",
    "test_eq(len(X_train), 64)\n",
    "test_eq(len(X_test), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = _prepare_data(learn)\n",
    "test_eq(len(X_train), 64)\n",
    "test_eq(len(X_test), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-748715efad6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-d6483a9be556>\u001b[0m in \u001b[0;36m_prepare_data\u001b[0;34m(learn, test_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input is not supported. Please use either a `DataFrame` or `TabularDataLoader`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mX_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input is not supported. Please use either a `DataFrame` or `TabularDataLoader`"
     ]
    }
   ],
   "source": [
    "X_train, X_test = _prepare_data(learn, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to grab predictions based on what shap throws back. This is a basic function you can use to get your predictions. We can't include it in the library as we need access to your current `Learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _predict(learn:TabularLearner, data:np.array):\n",
    "  \"Predict function for some data on a fastai model\"\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  model = learn.model.to(device)\n",
    "  dl = learn.dls[0]\n",
    "  nb_cat_cols = len(dl.dataset.cat_names)\n",
    "  nb_cont_cols = len(dl.dataset.cont_names)\n",
    "  x_cat = torch.from_numpy(data[:, :nb_cat_cols]).to(device, torch.int64)\n",
    "  x_cont = torch.from_numpy(data[:, -nb_cont_cols:]).to(device, torch.float32)\n",
    "  with torch.no_grad():\n",
    "    pred_probs = learn.model(x_cat, x_cont).cpu().numpy()\n",
    "  return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train.iloc[:5].to_numpy()\n",
    "pred_probs = _predict(learn, data)\n",
    "test_eq(pred_probs.shape, (5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can do whatever we need to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
